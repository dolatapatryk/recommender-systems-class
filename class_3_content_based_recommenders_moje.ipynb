{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content-based recommenders\n",
    "\n",
    "Content-based recommenders in their recommendations rely purely on the features of items. Conceptually it can be expressed as a model of the form (personalized):\n",
    "<center>\n",
    "$$\n",
    "    score \\sim (user, item\\_feature_1, item\\_feature_2, ..., item\\_feature_n)\n",
    "$$\n",
    "</center>\n",
    "or (not personalized)\n",
    "<center>\n",
    "$$\n",
    "    score \\sim (item\\_feature_1, item\\_feature_2, ..., item\\_feature_n)\n",
    "$$\n",
    "</center>\n",
    "\n",
    "    + Content-based recommenders do not suffer from the cold-start problem for new items.\n",
    "    - They do not use information about complex patterns of user-item interactions - what other similar users have already discovered and liked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import Markdown, display, HTML\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Fix the dying kernel problem (only a problem in some installations - you can remove it, if it works without it)\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Heat (1995)</td>\n",
       "      <td>Action|Crime|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Sabrina (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Tom and Huck (1995)</td>\n",
       "      <td>Adventure|Children</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Sudden Death (1995)</td>\n",
       "      <td>Action</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "      <td>Action|Adventure|Thriller</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of left interactions: 51980\n"
     ]
    }
   ],
   "source": [
    "ml_ratings_df = pd.read_csv(os.path.join(\"data\", \"movielens_small\", \"ratings.csv\")).rename(columns={'userId': 'user_id', 'movieId': 'item_id'})\n",
    "ml_movies_df = pd.read_csv(os.path.join(\"data\", \"movielens_small\", \"movies.csv\")).rename(columns={'movieId': 'item_id'})\n",
    "ml_df = pd.merge(ml_ratings_df, ml_movies_df, on='item_id')\n",
    "ml_df.head(10)\n",
    "\n",
    "display(HTML(ml_movies_df.head(10).to_html()))\n",
    "\n",
    "# Filter the data to reduce the number of movies\n",
    "rng = np.random.RandomState(seed=6789)\n",
    "left_ids = rng.choice(ml_movies_df['item_id'], size=5000, replace=False)\n",
    "ml_ratings_df = ml_ratings_df.loc[ml_ratings_df['item_id'].isin(left_ids)]\n",
    "ml_movies_df = ml_movies_df.loc[ml_movies_df['item_id'].isin(left_ids)]\n",
    "ml_df = ml_df.loc[ml_df['item_id'].isin(left_ids)]\n",
    "\n",
    "print(\"Number of left interactions: {}\".format(len(ml_ratings_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender class\n",
    "\n",
    "Remark: Docstrings written in reStructuredText (reST) used by Sphinx to automatically generate code documentation. It is also used by default by PyCharm (type triple quotes after defining a class or a method and hit enter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recommender(object):\n",
    "    \"\"\"\n",
    "    Base recommender class.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize base recommender params and variables.\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def fit(self, interactions_df, users_df, items_df):\n",
    "        \"\"\"\n",
    "        Training of the recommender.\n",
    "        \n",
    "        :param pd.DataFrame interactions_df: DataFrame with recorded interactions between users and items \n",
    "            defined by user_id, item_id and features of the interaction.\n",
    "        :param pd.DataFrame users_df: DataFrame with users and their features defined by user_id and the user feature columns.\n",
    "        :param pd.DataFrame items_df: DataFrame with items and their features defined by item_id and the item feature columns.\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def recommend(self, users_df, items_df, n_recommendations=1):\n",
    "        \"\"\"\n",
    "        Serving of recommendations. Scores items in items_df for each user in users_df and returns \n",
    "        top n_recommendations for each user.\n",
    "        \n",
    "        :param pd.DataFrame users_df: DataFrame with users and their features for which recommendations should be generated.\n",
    "        :param pd.DataFrame items_df: DataFrame with items and their features which should be scored.\n",
    "        :param int n_recommendations: Number of recommendations to be returned for each user.\n",
    "        :return: DataFrame with user_id, item_id and score as columns returning n_recommendations top recommendations \n",
    "            for each user.\n",
    "        :rtype: pd.DataFrame\n",
    "        \"\"\"\n",
    "        \n",
    "        recommendations = pd.DataFrame(columns=['user_id', 'item_id', 'score'])\n",
    "        \n",
    "        for ix, user in users_df.iterrows():\n",
    "            user_recommendations = pd.DataFrame({'user_id': user['user_id'],\n",
    "                                                 'item_id': [-1] * n_recommendations,\n",
    "                                                 'score': [3.0] * n_recommendations})\n",
    "\n",
    "            recommendations = pd.concat([recommendations, user_recommendations])\n",
    "\n",
    "        return recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explicit feedback - ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE - Root Mean Squared Error\n",
    "\n",
    "<center>\n",
    "$$\n",
    "    RMSE = \\sqrt{\\frac{\\sum_{i}^N (\\hat{r}_i - r_i)^2}{N}}\n",
    "$$\n",
    "</center>\n",
    "\n",
    "where $\\hat{r}_i$ are the predicted ratings and $r_i$ are the real ratings and $N$ is the number of items in the test set.\n",
    "\n",
    "    + Very well-behaved analytically and therefore extensively used to train models, especially neural networks.\n",
    "    - The scale of errors dependent on data which reduced comparability between different datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 1.33\n"
     ]
    }
   ],
   "source": [
    "def rmse(r_pred, r_real):\n",
    "    return np.sqrt(np.sum(np.power(r_pred - r_real, 2)) / len(r_pred))\n",
    "\n",
    "# Test\n",
    "\n",
    "print(\"RMSE = {:.2f}\".format(rmse(np.array([2.1, 1.2, 3.8, 4.2, 3.6]), np.array([3, 2, 4, 5, 1]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MRE - Mean Relative Error\n",
    "\n",
    "<center>\n",
    "$$\n",
    "    MRE = \\frac{1}{N} \\sum_{i}^N \\frac{|\\hat{r}_i - r_i|}{|r_i|}\n",
    "$$\n",
    "</center>\n",
    "\n",
    "where $\\hat{r}_i$ are the predicted ratings and $r_i$ are the real ratings and $N$ is the number of items in the test set.\n",
    "\n",
    "    + Easily interpretable (average percentage error) and with a meaning understandable for business.\n",
    "    - Blows up when there are values close to zero among the predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRE = 0.7020\n"
     ]
    }
   ],
   "source": [
    "def mre(r_pred, r_real):\n",
    "    return 1 / len(r_pred) * np.sum(np.abs(r_pred - r_real) / np.abs(r_real))\n",
    "\n",
    "# Test\n",
    "\n",
    "print(\"MRE = {:.4f}\".format(mre(np.array([2.1, 1.2, 3.8, 4.2, 3.6]), np.array([3, 2, 4, 5, 1]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRE - Total Relative Error\n",
    "\n",
    "<center>\n",
    "$$\n",
    "    TRE = \\frac{\\sum_{i}^N |\\hat{r}_i - r_i|}{\\sum_{i}^N |r_i|}\n",
    "$$\n",
    "</center>\n",
    "\n",
    "where $\\hat{r}_i$ are the predicted ratings and $r_i$ are the real ratings and $N$ is the number of items in the test set.\n",
    "\n",
    "    + Easily interpretable (total percentage error) and with a meaning understandable for business.\n",
    "    + Reliable even for very small predicted values.\n",
    "    - Does not distinguish between a case when one prediction is very bad and other are very good and a case when all predictions are mediocre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRE = 0.3533\n"
     ]
    }
   ],
   "source": [
    "def tre(r_pred, r_real):\n",
    "    return np.sum(np.abs(r_pred - r_real)) / np.sum(np.abs(r_real))\n",
    "\n",
    "# Test\n",
    "\n",
    "print(\"TRE = {:.4f}\".format(tre(np.array([2.1, 1.2, 3.8, 4.2, 3.6]), np.array([3, 2, 4, 5, 1]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implicit feedback - binary indicators of interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HR@n - Hit Ratio \n",
    "How many hits did we score in the first n recommendations.\n",
    "<br/>\n",
    "<br/>\n",
    "<center>\n",
    "$$\n",
    "    \\text{HR@}n = \\frac{\\sum_{u} \\sum_{i \\in I_u} r_{u, i} \\cdot 1_{\\hat{D}_n(u)}(i)}{M}\n",
    "$$\n",
    "</center>\n",
    "\n",
    "where:\n",
    "  * $r_{u, i}$ is $1$ if there was an interaction between user $u$ and item $i$ in the test set and $0$ otherwise, \n",
    "  * $\\hat{D}_n$ is the set of the first $n$ recommendations for user $u$, \n",
    "  * $1_{\\hat{D}_n}(i)$ is $1$ if and only if $i \\in \\hat{D}_n$, otherwise it's equal to $0$,\n",
    "  * $M$ is the number of users.\n",
    "\n",
    "\n",
    "    + Easily interpretable.\n",
    "    - Does not take the rank of each recommendation into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>77</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR@3 = 1.5000\n"
     ]
    }
   ],
   "source": [
    "def hr(recommendations, real_interactions, n=1):\n",
    "    \"\"\"\n",
    "    Assumes recommendations are ordered by user_id and then by score.\n",
    "    \"\"\"\n",
    "    # Transform real_interactions to a dict for a large speed-up\n",
    "    rui = defaultdict(lambda: 0)\n",
    "    \n",
    "    for idx, row in real_interactions.iterrows():\n",
    "        rui[(row['user_id'], row['item_id'])] = 1\n",
    "        \n",
    "    hr = 0.0\n",
    "    \n",
    "    previous_user_id = -1\n",
    "    rank = 0\n",
    "    for idx, row in recommendations.iterrows():\n",
    "        if previous_user_id == row['user_id']:\n",
    "            rank += 1\n",
    "        else:\n",
    "            rank = 1\n",
    "            \n",
    "        if rank <= n:\n",
    "            hr += rui[(row['user_id'], row['item_id'])]\n",
    "        \n",
    "        previous_user_id = row['user_id']\n",
    "    \n",
    "    hr /= len(recommendations['user_id'].unique())\n",
    "    \n",
    "    return hr\n",
    "\n",
    "    \n",
    "recommendations = pd.DataFrame(\n",
    "    [\n",
    "        [1, 13, 0.9],\n",
    "        [1, 45, 0.8],\n",
    "        [1, 22, 0.71],\n",
    "        [1, 77, 0.55],\n",
    "        [1, 9, 0.52],\n",
    "        [2, 11, 0.85],\n",
    "        [2, 13, 0.69],\n",
    "        [2, 25, 0.64],\n",
    "        [2, 6, 0.60],\n",
    "        [2, 77, 0.53]\n",
    "        \n",
    "    ], columns=['user_id', 'item_id', 'score'])\n",
    "\n",
    "display(HTML(recommendations.to_html()))\n",
    "\n",
    "real_interactions = pd.DataFrame(\n",
    "    [\n",
    "        [1, 45],\n",
    "        [1, 22],\n",
    "        [1, 77],\n",
    "        [2, 13],\n",
    "        [2, 77]\n",
    "        \n",
    "    ], columns=['user_id', 'item_id'])\n",
    "\n",
    "display(HTML(real_interactions.to_html()))\n",
    "    \n",
    "print(\"HR@3 = {:.4f}\".format(hr(recommendations, real_interactions, n=3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NDCG@n - Normalized Discounted Cumulative Gain\n",
    "\n",
    "How many hits did we score in the first n recommendations discounted by the position of each recommendation.\n",
    "<br/>\n",
    "<br/>\n",
    "<center>\n",
    "$$\n",
    "    \\text{NDCG@}n = \\frac{\\sum_{u} \\sum_{i \\in I_u} \\frac{r_{u, i}}{log\\left(1 + v_{\\hat{D}_n(u)}(i)\\right)}}{M}\n",
    "$$\n",
    "</center>\n",
    "\n",
    "where:\n",
    "  * $r_{u, i}$ is $1$ if there was an interaction between user $u$ and item $i$ in the test set and $0$ otherwise, \n",
    "  * $\\hat{D}_n(u)$ is the set of the first $n$ recommendations for user $u$, \n",
    "  * $v_{\\hat{D}_n(u)}(i)$ is the position of item $i$ in recommendations $\\hat{D}_n$,\n",
    "  * $M$ is the number of users.\n",
    "\n",
    "\n",
    "    - Takes the rank of each recommendation into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>77</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG@3 = 0.8809\n"
     ]
    }
   ],
   "source": [
    "def ndcg(recommendations, real_interactions, n=1):\n",
    "    \"\"\"\n",
    "    Assumes recommendations are ordered by user_id and then by score.\n",
    "    \"\"\"\n",
    "    # Transform real_interactions to a dict for a large speed-up\n",
    "    rui = defaultdict(lambda: 0)\n",
    "    \n",
    "    for idx, row in real_interactions.iterrows():\n",
    "        rui[(row['user_id'], row['item_id'])] = 1\n",
    "        \n",
    "    ndcg = 0.0\n",
    "    \n",
    "    previous_user_id = -1\n",
    "    rank = 0\n",
    "    for idx, row in recommendations.iterrows():\n",
    "        if previous_user_id == row['user_id']:\n",
    "            rank += 1\n",
    "        else:\n",
    "            rank = 1\n",
    "            \n",
    "        if rank <= n:\n",
    "            ndcg += rui[(row['user_id'], row['item_id'])] / np.log2(1 + rank)\n",
    "        \n",
    "        previous_user_id = row['user_id']\n",
    "    \n",
    "    ndcg /= len(recommendations['user_id'].unique())\n",
    "    \n",
    "    return ndcg\n",
    "\n",
    "    \n",
    "recommendations = pd.DataFrame(\n",
    "    [\n",
    "        [1, 13, 0.9],\n",
    "        [1, 45, 0.8],\n",
    "        [1, 22, 0.71],\n",
    "        [1, 77, 0.55],\n",
    "        [1, 9, 0.52],\n",
    "        [2, 11, 0.85],\n",
    "        [2, 13, 0.69],\n",
    "        [2, 25, 0.64],\n",
    "        [2, 6, 0.60],\n",
    "        [2, 77, 0.53]\n",
    "        \n",
    "    ], columns=['user_id', 'item_id', 'score'])\n",
    "\n",
    "display(HTML(recommendations.to_html()))\n",
    "\n",
    "real_interactions = pd.DataFrame(\n",
    "    [\n",
    "        [1, 45],\n",
    "        [1, 22],\n",
    "        [1, 77],\n",
    "        [2, 13],\n",
    "        [2, 77]\n",
    "        \n",
    "    ], columns=['user_id', 'item_id'])\n",
    "\n",
    "display(HTML(real_interactions.to_html()))\n",
    "    \n",
    "print(\"NDCG@3 = {:.4f}\".format(ndcg(recommendations, real_interactions, n=3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing routines (offline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test set split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explicit feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_train_test_split_explicit(recommender, interactions_df, items_df, seed=6789):\n",
    "    rng = np.random.RandomState(seed=seed)\n",
    "    \n",
    "    # Split the dataset into train and test\n",
    "    \n",
    "    shuffle = np.arange(len(interactions_df))\n",
    "    rng.shuffle(shuffle)\n",
    "    shuffle = list(shuffle)\n",
    "\n",
    "    train_test_split = 0.8\n",
    "    split_index = int(len(interactions_df) * train_test_split)\n",
    "\n",
    "    interactions_df_train = interactions_df.iloc[shuffle[:split_index]]\n",
    "    interactions_df_test = interactions_df.iloc[shuffle[split_index:]]\n",
    "    \n",
    "    # Train the recommender\n",
    "    print('before fit')\n",
    "    recommender.fit(interactions_df_train, None, items_df)\n",
    "    print('after fit')\n",
    "    \n",
    "    # Gather predictions\n",
    "    \n",
    "    r_pred = []\n",
    "    counter = 0\n",
    "    for idx, row in interactions_df_test.iterrows():\n",
    "        if counter % 1000 == 0:\n",
    "            print(\"counter = \", counter)\n",
    "        users_df = pd.DataFrame([row['user_id']], columns=['user_id'])\n",
    "        eval_items_df = pd.DataFrame([row['item_id']], columns=['item_id'])\n",
    "        eval_items_df = pd.merge(eval_items_df, items_df, on='item_id')\n",
    "        recommendations = recommender.recommend(users_df, eval_items_df, n_recommendations=1)\n",
    "        \n",
    "        r_pred.append(recommendations.iloc[0]['score'])\n",
    "        counter += 1\n",
    "    \n",
    "    # Gather real ratings\n",
    "    \n",
    "    r_real = np.array(interactions_df_test['rating'].tolist())\n",
    "    \n",
    "    # Return evaluation metrics\n",
    "    \n",
    "#     return rmse(r_pred, r_real), mre(r_pred, r_real), tre(r_pred, r_real)\n",
    "    print('end evaluate train test split explicit')\n",
    "    return rmse(r_pred, r_real)\n",
    "\n",
    "# recommender = Recommender()\n",
    "\n",
    "# results = [['BaseRecommender'] + list(evaluate_train_test_split_explicit(\n",
    "#     recommender, ml_ratings_df.loc[:, ['user_id', 'item_id', 'rating']], ml_movies_df))]\n",
    "\n",
    "# results = pd.DataFrame(results, \n",
    "#                        columns=['Recommender', 'RMSE', 'MRE', 'TRE'])\n",
    "\n",
    "# display(HTML(results.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implicit feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1.** Implement the following method for train-test split evaluation for implicit feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_train_test_split_implicit(recommender, interactions_df, items_df, seed=6789):\n",
    "    rng = np.random.RandomState(seed=seed)\n",
    "    \n",
    "    # Split the dataset into train and test\n",
    "    \n",
    "    shuffle = np.arange(len(interactions_df))\n",
    "    rng.shuffle(shuffle)\n",
    "    shuffle = list(shuffle)\n",
    "\n",
    "    train_test_split = 0.8\n",
    "    split_index = int(len(interactions_df) * train_test_split)\n",
    "\n",
    "    interactions_df_train = interactions_df.iloc[shuffle[:split_index]]\n",
    "    interactions_df_test = interactions_df.iloc[shuffle[split_index:]]\n",
    "    \n",
    "    # Train the recommender\n",
    "    \n",
    "    recommender.fit(interactions_df_train, None, items_df)\n",
    "    print('after fit')\n",
    "    # Gather predictions\n",
    "    \n",
    "    hr_1 = []\n",
    "#     hr_3 = []\n",
    "#     hr_5 = []\n",
    "    hr_10 = []\n",
    "#     ndcg_1 = []\n",
    "#     ndcg_3 = []\n",
    "#     ndcg_5 = []\n",
    "#     ndcg_10 = []\n",
    "    \n",
    "    counter = 0\n",
    "    for idx, row in interactions_df_test.iterrows():\n",
    "        if counter % 100 == 0:\n",
    "            print(\"counter = \", counter)\n",
    "        users_df = pd.DataFrame([row['user_id']], columns=['user_id'])\n",
    "        eval_items_df = pd.DataFrame([row['item_id']], columns=['item_id'])\n",
    "        eval_items_df = pd.merge(eval_items_df, items_df, on='item_id')\n",
    "#         recommendations = recommender.recommend(users_df, eval_items_df, n_recommendations=10)\n",
    "        recommendations = recommender.recommend(users_df, eval_items_df, n_recommendations=10)\n",
    "        \n",
    "        hr_1.append(hr(recommendations, interactions_df_test, n=1))\n",
    "#         hr_3.append(hr(recommendations, interactions_df_test, n=3))\n",
    "#         hr_5.append(hr(recommendations, interactions_df_test, n=5))\n",
    "        hr_10.append(hr(recommendations, interactions_df_test, n=10))\n",
    "#         ndcg_1.append(ndcg(recommendations, interactions_df_test, n=1))\n",
    "#         ndcg_3.append(ndcg(recommendations, interactions_df_test, n=3))\n",
    "#         ndcg_5.append(ndcg(recommendations, interactions_df_test, n=5))\n",
    "#         ndcg_10.append(ndcg(recommendations, interactions_df_test, n=10))\n",
    "        counter += 1\n",
    "    \n",
    "    # Return evaluation metrics\n",
    "    hr_1 = np.mean(hr_1)\n",
    "#     hr_3 = np.mean(hr_3)\n",
    "#     hr_5 = np.mean(hr_5)\n",
    "    hr_10 = np.mean(hr_10)\n",
    "#     ndcg_1 = np.mean(ndcg_1)\n",
    "#     ndcg_3 = np.mean(ndcg_3)\n",
    "#     ndcg_5 = np.mean(ndcg_5)\n",
    "#     ndcg_10 = np.mean(ndcg_10)\n",
    "    \n",
    "    return hr_1, hr_10\n",
    "\n",
    "# recommender = Recommender()\n",
    "\n",
    "# results = [['BaseRecommender'] + list(evaluate_train_test_split_implicit(\n",
    "#     recommender, ml_ratings_df.loc[:, ['user_id', 'item_id']], ml_movies_df))]\n",
    "\n",
    "# results = pd.DataFrame(results, \n",
    "#                        columns=['Recommender', 'HR@1', 'HR@3', 'HR@5', 'HR@10', 'NDCG@1', 'NDCG@3', 'NDCG@5', 'NDCG@10'])\n",
    "\n",
    "# display(HTML(results.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave-one-out, leave-k-out, cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explicit feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2.** Implement the following method for leave-one-out evaluation for explicit feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_leave_one_out_explicit(recommender, interactions_df, items_df, max_evals=100, seed=6789):\n",
    "    rng = np.random.RandomState(seed=seed)\n",
    "\n",
    "    shuffle = np.arange(len(interactions_df))\n",
    "    rng.shuffle(shuffle)\n",
    "    shuffle = list(shuffle)\n",
    "    interactions_df = interactions_df.iloc[shuffle]\n",
    "\n",
    "    # Prepare splits of the datasets\n",
    "    kf = KFold(n_splits=len(interactions_df), random_state=rng, shuffle=True)\n",
    "\n",
    "\n",
    "    rmse_1 = []\n",
    "    mre_1 = []\n",
    "    tre_1 = []\n",
    "    # For each split of the dataset train the recommender, generate recommendations and evaluate\n",
    "\n",
    "    n_eval = 1\n",
    "    for train_index, test_index in kf.split(interactions_df.index):\n",
    "        interactions_df_train = interactions_df.loc[interactions_df.index[train_index]]\n",
    "        interactions_df_test = interactions_df.loc[interactions_df.index[test_index]]\n",
    "\n",
    "        recommender.fit(interactions_df_train, None, items_df)\n",
    "        recommendations = recommender.recommend(interactions_df_test.loc[:, ['user_id']], items_df, n_recommendations=10)\n",
    "\n",
    "\n",
    "        r_real = np.array(interactions_df_test['rating'].tolist()) \n",
    "        r_pred = ([recommendations.iloc[0]['score']])\n",
    "\n",
    "        rmse_1.append(rmse(r_pred, r_real))\n",
    "\n",
    "        mre_1.append(mre(r_pred, r_real))\n",
    "\n",
    "\n",
    "        tre_1.append(tre(r_pred, r_real))\n",
    "\n",
    "        if n_eval == max_evals:\n",
    "            break\n",
    "        n_eval += 1\n",
    "\n",
    "\n",
    "    rmse_1 = np.mean(rmse_1)\n",
    "    mre_1 = np.mean(mre_1)\n",
    "    tre_1 = np.mean(tre_1)\n",
    "\n",
    "\n",
    "    return rmse_1,mre_1,tre_1\n",
    "\n",
    "\n",
    "# recommender = LinearRegressionRecommender()\n",
    "\n",
    "\n",
    "# results = [['BaseRecommender'] + list(evaluate_leave_one_out_explicit(\n",
    "#     recommender, ml_ratings_df.loc[:, ['user_id', 'item_id','rating']], ml_movies_df))]\n",
    "\n",
    "# results = pd.DataFrame(results, \n",
    "#                        columns=['Recommender', 'rmse@1', 'mre@1','tre@1'])\n",
    "\n",
    "# display(HTML(results.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implicit feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recommender</th>\n",
       "      <th>HR@1</th>\n",
       "      <th>HR@3</th>\n",
       "      <th>HR@5</th>\n",
       "      <th>HR@10</th>\n",
       "      <th>NDCG@1</th>\n",
       "      <th>NDCG@3</th>\n",
       "      <th>NDCG@5</th>\n",
       "      <th>NDCG@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaseRecommender</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def evaluate_leave_one_out_implicit(recommender, interactions_df, items_df, max_evals=10, seed=6789):\n",
    "    rng = np.random.RandomState(seed=seed)\n",
    "    \n",
    "    # Prepare splits of the datasets\n",
    "    kf = KFold(n_splits=len(interactions_df), random_state=rng, shuffle=True)\n",
    "    \n",
    "    hr_1 = []\n",
    "    hr_3 = []\n",
    "    hr_5 = []\n",
    "    hr_10 = []\n",
    "    ndcg_1 = []\n",
    "    ndcg_3 = []\n",
    "    ndcg_5 = []\n",
    "    ndcg_10 = []\n",
    "    \n",
    "    # For each split of the dataset train the recommender, generate recommendations and evaluate\n",
    "    \n",
    "    n_eval = 1\n",
    "    for train_index, test_index in kf.split(interactions_df.index):\n",
    "        interactions_df_train = interactions_df.loc[interactions_df.index[train_index]]\n",
    "        interactions_df_test = interactions_df.loc[interactions_df.index[test_index]]\n",
    "                \n",
    "        recommender.fit(interactions_df_train, None, items_df)\n",
    "        recommendations = recommender.recommend(interactions_df_test.loc[:, ['user_id']], items_df, n_recommendations=10)\n",
    "        \n",
    "        hr_1.append(hr(recommendations, interactions_df_test, n=1))\n",
    "        hr_3.append(hr(recommendations, interactions_df_test, n=3))\n",
    "        hr_5.append(hr(recommendations, interactions_df_test, n=5))\n",
    "        hr_10.append(hr(recommendations, interactions_df_test, n=10))\n",
    "        ndcg_1.append(ndcg(recommendations, interactions_df_test, n=1))\n",
    "        ndcg_3.append(ndcg(recommendations, interactions_df_test, n=3))\n",
    "        ndcg_5.append(ndcg(recommendations, interactions_df_test, n=5))\n",
    "        ndcg_10.append(ndcg(recommendations, interactions_df_test, n=10))\n",
    "        \n",
    "        if n_eval == max_evals:\n",
    "            break\n",
    "        n_eval += 1\n",
    "        \n",
    "    hr_1 = np.mean(hr_1)\n",
    "    hr_3 = np.mean(hr_3)\n",
    "    hr_5 = np.mean(hr_5)\n",
    "    hr_10 = np.mean(hr_10)\n",
    "    ndcg_1 = np.mean(ndcg_1)\n",
    "    ndcg_3 = np.mean(ndcg_3)\n",
    "    ndcg_5 = np.mean(ndcg_5)\n",
    "    ndcg_10 = np.mean(ndcg_10)\n",
    "    \n",
    "    return hr_1, hr_3, hr_5, hr_10, ndcg_1, ndcg_3, ndcg_5, ndcg_10\n",
    "\n",
    "recommender = Recommender()\n",
    "\n",
    "results = [['BaseRecommender'] + list(evaluate_leave_one_out_implicit(\n",
    "    recommender, ml_ratings_df.loc[:, ['user_id', 'item_id']], ml_movies_df))]\n",
    "\n",
    "results = pd.DataFrame(results, \n",
    "                       columns=['Recommender', 'HR@1', 'HR@3', 'HR@5', 'HR@10', 'NDCG@1', 'NDCG@3', 'NDCG@5', 'NDCG@10'])\n",
    "\n",
    "display(HTML(results.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Recommender\n",
    "\n",
    "For every movie we transform its genres into one-hot encoded features and then fit a linear regression model to those features and actual ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "class LinearRegressionRecommender(object):\n",
    "    \"\"\"\n",
    "    Base recommender class.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize base recommender params and variables.\n",
    "        \"\"\"\n",
    "        self.model = None\n",
    "        self.mlb = None\n",
    "    \n",
    "    def fit(self, interactions_df, users_df, items_df):\n",
    "        \"\"\"\n",
    "        Training of the recommender.\n",
    "        \n",
    "        :param pd.DataFrame interactions_df: DataFrame with recorded interactions between users and items \n",
    "            defined by user_id, item_id and features of the interaction.\n",
    "        :param pd.DataFrame users_df: DataFrame with users and their features defined by user_id and the user feature columns.\n",
    "        :param pd.DataFrame items_df: DataFrame with items and their features defined by item_id and the item feature columns.\n",
    "        \"\"\"\n",
    "        \n",
    "        interactions_df = pd.merge(interactions_df, items_df, on='item_id')\n",
    "        interactions_df.loc[:, 'genres'] = interactions_df['genres'].str.replace(\"-\", \"_\", regex=False)\n",
    "        interactions_df.loc[:, 'genres'] = interactions_df['genres'].str.replace(\" \", \"_\", regex=False)\n",
    "        interactions_df.loc[:, 'genres'] = interactions_df['genres'].str.lower()\n",
    "        interactions_df.loc[:, 'genres'] = interactions_df['genres'].str.split(\"|\")\n",
    "        \n",
    "        self.mlb = MultiLabelBinarizer()\n",
    "        interactions_df = interactions_df.join(\n",
    "            pd.DataFrame(self.mlb.fit_transform(interactions_df.pop('genres')),\n",
    "                         columns=self.mlb.classes_,\n",
    "                         index=interactions_df.index))\n",
    "        \n",
    "#         print(interactions_df.head())\n",
    "        \n",
    "        x = interactions_df.loc[:, self.mlb.classes_].values\n",
    "        y = interactions_df['rating'].values\n",
    "    \n",
    "        self.model = LinearRegression().fit(x, y)\n",
    "    \n",
    "    def recommend(self, users_df, items_df, n_recommendations=1):\n",
    "        \"\"\"\n",
    "        Serving of recommendations. Scores items in items_df for each user in users_df and returns \n",
    "        top n_recommendations for each user.\n",
    "        \n",
    "        :param pd.DataFrame users_df: DataFrame with users and their features for which recommendations should be generated.\n",
    "        :param pd.DataFrame items_df: DataFrame with items and their features which should be scored.\n",
    "        :param int n_recommendations: Number of recommendations to be returned for each user.\n",
    "        :return: DataFrame with user_id, item_id and score as columns returning n_recommendations top recommendations \n",
    "            for each user.\n",
    "        :rtype: pd.DataFrame\n",
    "        \"\"\"\n",
    "        \n",
    "        # Transform the item to be scored into proper features\n",
    "        \n",
    "        items_df = items_df.copy()\n",
    "        items_df.loc[:, 'genres'] = items_df['genres'].str.replace(\"-\", \"_\", regex=False)\n",
    "        items_df.loc[:, 'genres'] = items_df['genres'].str.replace(\" \", \"_\", regex=False)\n",
    "        items_df.loc[:, 'genres'] = items_df['genres'].str.lower()\n",
    "        items_df.loc[:, 'genres'] = items_df['genres'].str.split(\"|\")\n",
    "        \n",
    "        items_df = items_df.join(\n",
    "            pd.DataFrame(self.mlb.transform(items_df.pop('genres')),\n",
    "                         columns=self.mlb.classes_,\n",
    "                         index=items_df.index))\n",
    "        \n",
    "#         print(items_df)\n",
    "        \n",
    "        # Score the item\n",
    "    \n",
    "        recommendations = pd.DataFrame(columns=['user_id', 'item_id', 'score'])\n",
    "        \n",
    "        for ix, user in users_df.iterrows():\n",
    "            score = self.model.predict(items_df.loc[:, self.mlb.classes_].values)[0]\n",
    "                \n",
    "            user_recommendations = pd.DataFrame({'user_id': [user['user_id']],\n",
    "                                                 'item_id': items_df.iloc[0]['item_id'],\n",
    "                                                 'score': score})\n",
    "\n",
    "            recommendations = pd.concat([recommendations, user_recommendations])\n",
    "\n",
    "        return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>score</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>3.282778</td>\n",
       "      <td>Bad Boys (1995)</td>\n",
       "      <td>Action|Comedy|Crime|Drama|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>145</td>\n",
       "      <td>3.282778</td>\n",
       "      <td>Bad Boys (1995)</td>\n",
       "      <td>Action|Comedy|Crime|Drama|Thriller</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Quick test of the recommender\n",
    "\n",
    "lr_recommender = LinearRegressionRecommender()\n",
    "lr_recommender.fit(ml_ratings_df, None, ml_movies_df)\n",
    "recommendations = lr_recommender.recommend(pd.DataFrame([[1], [2]], columns=['user_id']), ml_movies_df, 1)\n",
    "\n",
    "recommendations = pd.merge(recommendations, ml_movies_df, on='item_id')\n",
    "display(HTML(recommendations.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recommender</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MRE</th>\n",
       "      <th>TRE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegressionRecommender</td>\n",
       "      <td>1.019263</td>\n",
       "      <td>0.370077</td>\n",
       "      <td>0.245447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr_recommender = LinearRegressionRecommender()\n",
    "\n",
    "results = [['LinearRegressionRecommender'] + list(evaluate_train_test_split_explicit(\n",
    "    lr_recommender, ml_ratings_df.loc[:, ['user_id', 'item_id', 'rating']], ml_movies_df, seed=6789))]\n",
    "\n",
    "results = pd.DataFrame(results, \n",
    "                       columns=['Recommender', 'RMSE', 'MRE', 'TRE'])\n",
    "\n",
    "display(HTML(results.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recommender</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MRE</th>\n",
       "      <th>TRE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegressionRecommender</td>\n",
       "      <td>0.217481</td>\n",
       "      <td>0.062129</td>\n",
       "      <td>18.638603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr_recommender = LinearRegressionRecommender()\n",
    "\n",
    "results = [['LinearRegressionRecommender'] + list(evaluate_leave_one_out_explicit(\n",
    "    lr_recommender, ml_ratings_df.loc[:, ['user_id', 'item_id', 'rating']], ml_movies_df, seed=6789))]\n",
    "\n",
    "results = pd.DataFrame(results, \n",
    "                       columns=['Recommender', 'RMSE', 'MRE', 'TRE'])\n",
    "\n",
    "display(HTML(results.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF Recommender\n",
    "TF-IDF stands for term frequencyâ€“inverse document frequency. Typically Tf-IDF method is used to assign keywords (words describing the gist of a document) to documents in a corpus of documents.\n",
    "\n",
    "In our case we will treat users as documents and genres as words.\n",
    "\n",
    "Term-frequency is given by the following formula:\n",
    "<center>\n",
    "$$\n",
    "    \\text{tf}(g, u) = f_{g, u}\n",
    "$$\n",
    "</center>\n",
    "where $f_{g, i}$ is the number of times genre $g$ appear for movies watched by user $u$.\n",
    "\n",
    "Inverse document frequency is defined as follows:\n",
    "<center>\n",
    "$$\n",
    "    \\text{idf}(g) = \\log \\frac{N}{n_g}\n",
    "$$\n",
    "</center>\n",
    "where $N$ is the number of users and $n_g$ is the number of users with $g$ in their genres list.\n",
    "\n",
    "Finally, tf-idf is defined as follows:\n",
    "<center>\n",
    "$$\n",
    "    \\text{tfidf}(g, u) = \\text{tf}(g, u) \\cdot \\text{idf}(g)\n",
    "$$\n",
    "</center>\n",
    "\n",
    "In our case we will measure how often a given genre appears for movies watched by a given user vs how often it appears for all users. To obtain a movie score we will take the average of its genres' scores for this user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "class TFIDFRecommender(object):\n",
    "    \"\"\"\n",
    "    Recommender based on the TF-IDF method.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize base recommender params and variables.\n",
    "        \"\"\"\n",
    "        self.tfidf_scores = None\n",
    "    \n",
    "    def fit(self, interactions_df, users_df, items_df):\n",
    "        \"\"\"\n",
    "        Training of the recommender.\n",
    "        \n",
    "        :param pd.DataFrame interactions_df: DataFrame with recorded interactions between users and items \n",
    "            defined by user_id, item_id and features of the interaction.\n",
    "        :param pd.DataFrame users_df: DataFrame with users and their features defined by user_id and the user feature columns.\n",
    "        :param pd.DataFrame items_df: DataFrame with items and their features defined by item_id and the item feature columns.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.tfidf_scores = defaultdict(lambda: 0.0)\n",
    "\n",
    "        # Prepare the corpus for tfidf calculation\n",
    "        \n",
    "        interactions_df = pd.merge(interactions_df, items_df, on='item_id')\n",
    "        user_genres = interactions_df.loc[:, ['user_id', 'genres']]\n",
    "        user_genres.loc[:, 'genres'] = user_genres['genres'].str.replace(\"-\", \"_\", regex=False)\n",
    "        user_genres.loc[:, 'genres'] = user_genres['genres'].str.replace(\" \", \"_\", regex=False)\n",
    "        user_genres = user_genres.groupby('user_id').aggregate(lambda x: \"|\".join(x))\n",
    "        user_genres.loc[:, 'genres'] = user_genres['genres'].str.replace(\"|\", \" \", regex=False)\n",
    "#         print(user_genres)\n",
    "        user_ids = user_genres.index.tolist()\n",
    "        genres_corpus = user_genres['genres'].tolist()\n",
    "        \n",
    "        # Calculate tf-idf scores\n",
    "        \n",
    "        vectorizer = TfidfVectorizer()\n",
    "        tfidf_scores = vectorizer.fit_transform(genres_corpus)\n",
    "        \n",
    "        # Transform results into a dict {(user_id, genre): score}\n",
    "        \n",
    "        for u in range(tfidf_scores.shape[0]):\n",
    "            for g in range(tfidf_scores.shape[1]):\n",
    "                self.tfidf_scores[(user_ids[u], vectorizer.get_feature_names()[g])] = tfidf_scores[u, g]\n",
    "                \n",
    "#         print(self.tfidf_scores)\n",
    "    \n",
    "    def recommend(self, users_df, items_df, n_recommendations=1):\n",
    "        \"\"\"\n",
    "        Serving of recommendations. Scores items in items_df for each user in users_df and returns \n",
    "        top n_recommendations for each user.\n",
    "        \n",
    "        :param pd.DataFrame users_df: DataFrame with users and their features for which recommendations should be generated.\n",
    "        :param pd.DataFrame items_df: DataFrame with items and their features which should be scored.\n",
    "        :param int n_recommendations: Number of recommendations to be returned for each user.\n",
    "        :return: DataFrame with user_id, item_id and score as columns returning n_recommendations top recommendations \n",
    "            for each user.\n",
    "        :rtype: pd.DataFrame\n",
    "        \"\"\"\n",
    "        \n",
    "        recommendations = pd.DataFrame(columns=['user_id', 'item_id', 'score'])\n",
    "        \n",
    "        # Transform genres to a unified form used by the vectorizer\n",
    "        \n",
    "        items_df = items_df.copy()\n",
    "        items_df.loc[:, 'genres'] = items_df['genres'].str.replace(\"-\", \"_\", regex=False)\n",
    "        items_df.loc[:, 'genres'] = items_df['genres'].str.replace(\" \", \"_\", regex=False)\n",
    "        items_df.loc[:, 'genres'] = items_df['genres'].str.lower()\n",
    "        items_df.loc[:, 'genres'] = items_df['genres'].str.split(\"|\")\n",
    "                \n",
    "        # Score items    \n",
    "        \n",
    "        for uix, user in users_df.iterrows():\n",
    "            items = []\n",
    "            for iix, item in items_df.iterrows():\n",
    "                score = 0.0\n",
    "                for genre in item['genres']:\n",
    "                    score += self.tfidf_scores[(user['user_id'], genre)]\n",
    "                score /= len(item['genres'])\n",
    "                items.append((item['item_id'], score))\n",
    "                \n",
    "            items = sorted(items, key=lambda x: x[1], reverse=True)\n",
    "            user_recommendations = pd.DataFrame({'user_id': user['user_id'],\n",
    "                                                 'item_id': [item[0] for item in items][:n_recommendations],\n",
    "                                                 'score': [item[1] for item in items][:n_recommendations]})\n",
    "\n",
    "            recommendations = pd.concat([recommendations, user_recommendations])\n",
    "\n",
    "        return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>score</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2690</td>\n",
       "      <td>0.452122</td>\n",
       "      <td>Ideal Husband, An (1999)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3614</td>\n",
       "      <td>0.452122</td>\n",
       "      <td>Honeymoon in Vegas (1992)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4796</td>\n",
       "      <td>0.452122</td>\n",
       "      <td>Grass Is Greener, The (1960)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>145</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Bad Boys (1995)</td>\n",
       "      <td>Action|Comedy|Crime|Drama|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>171</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Jeffrey (1995)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>228</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Destiny Turns on the Radio (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Quick test of the recommender\n",
    "\n",
    "tfidf_recommender = TFIDFRecommender()\n",
    "tfidf_recommender.fit(ml_ratings_df, None, ml_movies_df)\n",
    "recommendations = tfidf_recommender.recommend(pd.DataFrame([[1], [2]], columns=['user_id']), ml_movies_df, 3)\n",
    "\n",
    "recommendations = pd.merge(recommendations, ml_movies_df, on='item_id')\n",
    "display(HTML(recommendations.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recommender</th>\n",
       "      <th>HR@1</th>\n",
       "      <th>HR@3</th>\n",
       "      <th>HR@5</th>\n",
       "      <th>HR@10</th>\n",
       "      <th>NDCG@1</th>\n",
       "      <th>NDCG@3</th>\n",
       "      <th>NDCG@5</th>\n",
       "      <th>NDCG@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TFIDFRecommender</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042062</td>\n",
       "      <td>0.042062</td>\n",
       "      <td>0.042062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tfidf_recommender = TFIDFRecommender()\n",
    "\n",
    "results = [['TFIDFRecommender'] + list(evaluate_leave_one_out_implicit(\n",
    "    tfidf_recommender, ml_ratings_df.loc[:, ['user_id', 'item_id']], ml_movies_df, max_evals=300, seed=6789))]\n",
    "\n",
    "results = pd.DataFrame(results, \n",
    "                       columns=['Recommender', 'HR@1', 'HR@3', 'HR@5', 'HR@10', 'NDCG@1', 'NDCG@3', 'NDCG@5', 'NDCG@10'])\n",
    "\n",
    "display(HTML(results.head(10).to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after fit\n",
      "counter =  0\n",
      "counter =  100\n",
      "counter =  200\n",
      "counter =  300\n",
      "counter =  400\n",
      "counter =  500\n",
      "counter =  600\n",
      "counter =  700\n",
      "counter =  800\n",
      "counter =  900\n",
      "counter =  1000\n",
      "counter =  1100\n",
      "counter =  1200\n",
      "counter =  1300\n",
      "counter =  1400\n",
      "counter =  1500\n",
      "counter =  1600\n",
      "counter =  1700\n",
      "counter =  1800\n",
      "counter =  1900\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recommender</th>\n",
       "      <th>HR@1</th>\n",
       "      <th>HR@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TFIDFRecommender</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tfidf_recommender = TFIDFRecommender()\n",
    "\n",
    "results = [['TFIDFRecommender'] + list(evaluate_train_test_split_implicit(\n",
    "    tfidf_recommender, ml_ratings_df.loc[:, ['user_id', 'item_id', 'rating']], ml_movies_df))]\n",
    "results = pd.DataFrame(results, \n",
    "                       columns=['Recommender', 'HR@1', 'HR@10'])\n",
    "display(HTML(results.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3.** Implement the MostPopularRecommender (check the slides for class 1), evaluate it with leave-one-out procedure for implicit feedback, print HR@1, HR@3, HR@5, HR@10, NDCG@1, NDCG@3, NDCG@5, NDCG@10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recommender</th>\n",
       "      <th>HR@1</th>\n",
       "      <th>HR@3</th>\n",
       "      <th>HR@5</th>\n",
       "      <th>HR@10</th>\n",
       "      <th>NDCG@1</th>\n",
       "      <th>NDCG@3</th>\n",
       "      <th>NDCG@5</th>\n",
       "      <th>NDCG@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MostPopularRecommender</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.163333</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.040079</td>\n",
       "      <td>0.053997</td>\n",
       "      <td>0.079749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Write your code here\n",
    "class MostPopularRecommender(object):\n",
    "    \"\"\"\n",
    "    Most popular recommender class.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize base recommender params and variables.\n",
    "        \"\"\"\n",
    "        self.most_popular = []\n",
    "        pass\n",
    "    \n",
    "    def fit(self, interactions_df, users_df, items_df):\n",
    "        \"\"\"\n",
    "        Training of the recommender.\n",
    "        \n",
    "        :param pd.DataFrame interactions_df: DataFrame with recorded interactions between users and items \n",
    "            defined by user_id, item_id and features of the interaction.\n",
    "        :param pd.DataFrame users_df: DataFrame with users and their features defined by user_id and the user feature columns.\n",
    "        :param pd.DataFrame items_df: DataFrame with items and their features defined by item_id and the item feature columns.\n",
    "        \"\"\"\n",
    "        grouped = interactions_df.groupby('item_id').count().sort_values(by='user_id', ascending=False)\n",
    "        self.most_popular = list(grouped.index)\n",
    "    \n",
    "    def recommend(self, users_df, items_df, n_recommendations=1):\n",
    "        \"\"\"\n",
    "        Serving of recommendations. Scores items in items_df for each user in users_df and returns \n",
    "        top n_recommendations for each user.\n",
    "        \n",
    "        :param pd.DataFrame users_df: DataFrame with users and their features for which recommendations should be generated.\n",
    "        :param pd.DataFrame items_df: DataFrame with items and their features which should be scored.\n",
    "        :param int n_recommendations: Number of recommendations to be returned for each user.\n",
    "        :return: DataFrame with user_id, item_id and score as columns returning n_recommendations top recommendations \n",
    "            for each user.\n",
    "        :rtype: pd.DataFrame\n",
    "        \"\"\"\n",
    "        \n",
    "        recommendations = pd.DataFrame(columns=['user_id', 'item_id', 'score'])\n",
    "        \n",
    "        for ix, user in users_df.iterrows():\n",
    "            user_recommendations = pd.DataFrame({'user_id': user['user_id'],\n",
    "                                                 'item_id': self.most_popular[:n_recommendations],\n",
    "                                                 'score': [3.0] * n_recommendations})\n",
    "\n",
    "            recommendations = pd.concat([recommendations, user_recommendations])\n",
    "\n",
    "        return recommendations\n",
    "\n",
    "recommender = MostPopularRecommender()\n",
    "results = [['MostPopularRecommender'] + list(evaluate_leave_one_out_implicit(\n",
    "    recommender, ml_ratings_df.loc[:, ['user_id', 'item_id']], ml_movies_df, max_evals=300, seed=6789))]\n",
    "\n",
    "results = pd.DataFrame(results, \n",
    "                       columns=['Recommender', 'HR@1', 'HR@3', 'HR@5', 'HR@10', 'NDCG@1', 'NDCG@3', 'NDCG@5', 'NDCG@10'])\n",
    "\n",
    "display(HTML(results.head(10).to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4.** Implement the HighestRatedRecommender (check the slides for class 1), evaluate it with leave-one-out procedure for implicit feedback, print HR@1, HR@3, HR@5, HR@10, NDCG@1, NDCG@3, NDCG@5, NDCG@10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recommender</th>\n",
       "      <th>HR@1</th>\n",
       "      <th>HR@3</th>\n",
       "      <th>HR@5</th>\n",
       "      <th>HR@10</th>\n",
       "      <th>NDCG@1</th>\n",
       "      <th>NDCG@3</th>\n",
       "      <th>NDCG@5</th>\n",
       "      <th>NDCG@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HighestRatedRecommender</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Write your code here\n",
    "class HighestRatedRecommender(object):\n",
    "    \"\"\"\n",
    "    Highest rated recommender class.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize base recommender params and variables.\n",
    "        \"\"\"\n",
    "        self.highest_rated = []\n",
    "        pass\n",
    "    \n",
    "    def fit(self, interactions_df, users_df, items_df):\n",
    "        \"\"\"\n",
    "        Training of the recommender.\n",
    "        \n",
    "        :param pd.DataFrame interactions_df: DataFrame with recorded interactions between users and items \n",
    "            defined by user_id, item_id and features of the interaction.\n",
    "        :param pd.DataFrame users_df: DataFrame with users and their features defined by user_id and the user feature columns.\n",
    "        :param pd.DataFrame items_df: DataFrame with items and their features defined by item_id and the item feature columns.\n",
    "        \"\"\"\n",
    "        grouped = interactions_df.groupby('item_id').mean('rating').sort_values(by='rating', ascending=False)\n",
    "        self.highest_rated = list(grouped.index)\n",
    "    \n",
    "    def recommend(self, users_df, items_df, n_recommendations=1):\n",
    "        \"\"\"\n",
    "        Serving of recommendations. Scores items in items_df for each user in users_df and returns \n",
    "        top n_recommendations for each user.\n",
    "        \n",
    "        :param pd.DataFrame users_df: DataFrame with users and their features for which recommendations should be generated.\n",
    "        :param pd.DataFrame items_df: DataFrame with items and their features which should be scored.\n",
    "        :param int n_recommendations: Number of recommendations to be returned for each user.\n",
    "        :return: DataFrame with user_id, item_id and score as columns returning n_recommendations top recommendations \n",
    "            for each user.\n",
    "        :rtype: pd.DataFrame\n",
    "        \"\"\"\n",
    "        \n",
    "        recommendations = pd.DataFrame(columns=['user_id', 'item_id', 'score'])\n",
    "        \n",
    "        for ix, user in users_df.iterrows():\n",
    "            user_recommendations = pd.DataFrame({'user_id': user['user_id'],\n",
    "                                                 'item_id': self.highest_rated[:n_recommendations],\n",
    "                                                 'score': [3.0] * n_recommendations})\n",
    "\n",
    "            recommendations = pd.concat([recommendations, user_recommendations])\n",
    "\n",
    "        return recommendations\n",
    "\n",
    "recommender = HighestRatedRecommender()\n",
    "results = [['HighestRatedRecommender'] + list(evaluate_leave_one_out_implicit(\n",
    "    recommender, ml_ratings_df.loc[:, ['user_id', 'item_id', 'rating']], ml_movies_df, max_evals=300, seed=6789))]\n",
    "\n",
    "results = pd.DataFrame(results, \n",
    "                       columns=['Recommender', 'HR@1', 'HR@3', 'HR@5', 'HR@10', 'NDCG@1', 'NDCG@3', 'NDCG@5', 'NDCG@10'])\n",
    "\n",
    "display(HTML(results.head(10).to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 5.** Implement the RandomRecommender (check the slides for class 1), evaluate it with leave-one-out procedure for implicit feedback, print HR@1, HR@3, HR@5, HR@10, NDCG@1, NDCG@3, NDCG@5, NDCG@10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recommender</th>\n",
       "      <th>HR@1</th>\n",
       "      <th>HR@3</th>\n",
       "      <th>HR@5</th>\n",
       "      <th>HR@10</th>\n",
       "      <th>NDCG@1</th>\n",
       "      <th>NDCG@3</th>\n",
       "      <th>NDCG@5</th>\n",
       "      <th>NDCG@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomRecommender</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.003102</td>\n",
       "      <td>0.003102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Write your code here\n",
    "# Write your code here\n",
    "class RandomRecommender(object):\n",
    "    \"\"\"\n",
    "    Random recommender class.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize base recommender params and variables.\n",
    "        \"\"\"\n",
    "        self.shuffled = []\n",
    "        self.rng = np.random.RandomState(seed=6789)\n",
    "        pass\n",
    "    \n",
    "    def fit(self, interactions_df, users_df, items_df):\n",
    "        \"\"\"\n",
    "        Training of the recommender.\n",
    "        \n",
    "        :param pd.DataFrame interactions_df: DataFrame with recorded interactions between users and items \n",
    "            defined by user_id, item_id and features of the interaction.\n",
    "        :param pd.DataFrame users_df: DataFrame with users and their features defined by user_id and the user feature columns.\n",
    "        :param pd.DataFrame items_df: DataFrame with items and their features defined by item_id and the item feature columns.\n",
    "        \"\"\"\n",
    "        shuffle = np.arange(len(items_df))\n",
    "        self.rng.shuffle(shuffle)\n",
    "        shuffle = list(shuffle)\n",
    "        \n",
    "        self.shuffled = [items_df.iloc[x]['item_id'] for x in shuffle]\n",
    "    \n",
    "    def recommend(self, users_df, items_df, n_recommendations=1):\n",
    "        \"\"\"\n",
    "        Serving of recommendations. Scores items in items_df for each user in users_df and returns \n",
    "        top n_recommendations for each user.\n",
    "        \n",
    "        :param pd.DataFrame users_df: DataFrame with users and their features for which recommendations should be generated.\n",
    "        :param pd.DataFrame items_df: DataFrame with items and their features which should be scored.\n",
    "        :param int n_recommendations: Number of recommendations to be returned for each user.\n",
    "        :return: DataFrame with user_id, item_id and score as columns returning n_recommendations top recommendations \n",
    "            for each user.\n",
    "        :rtype: pd.DataFrame\n",
    "        \"\"\"\n",
    "        \n",
    "        recommendations = pd.DataFrame(columns=['user_id', 'item_id', 'score'])\n",
    "        \n",
    "        for ix, user in users_df.iterrows():\n",
    "            user_recommendations = pd.DataFrame({'user_id': user['user_id'],\n",
    "                                                 'item_id': self.shuffled[:n_recommendations],\n",
    "                                                 'score': [3.0] * n_recommendations})\n",
    "\n",
    "            recommendations = pd.concat([recommendations, user_recommendations])\n",
    "\n",
    "        return recommendations\n",
    "\n",
    "recommender = RandomRecommender()\n",
    "recommender.fit(ml_ratings_df.loc[:, ['user_id', 'item_id', 'rating']], None, ml_movies_df)\n",
    "results = [['RandomRecommender'] + list(evaluate_leave_one_out_implicit(\n",
    "    recommender, ml_ratings_df.loc[:, ['user_id', 'item_id', 'rating']], ml_movies_df, max_evals=300, seed=6789))]\n",
    "\n",
    "results = pd.DataFrame(results, \n",
    "                       columns=['Recommender', 'HR@1', 'HR@3', 'HR@5', 'HR@10', 'NDCG@1', 'NDCG@3', 'NDCG@5', 'NDCG@10'])\n",
    "\n",
    "display(HTML(results.head(10).to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 6.** Gather the results for TFIDFRecommender, MostPopularRecommender, HighestRatedRecommender, RandomRecommender in one DataFrame and print it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recommender</th>\n",
       "      <th>HR@1</th>\n",
       "      <th>HR@3</th>\n",
       "      <th>HR@5</th>\n",
       "      <th>HR@10</th>\n",
       "      <th>NDCG@1</th>\n",
       "      <th>NDCG@3</th>\n",
       "      <th>NDCG@5</th>\n",
       "      <th>NDCG@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TFIDFRecommender</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>0.123333</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.033491</td>\n",
       "      <td>0.062178</td>\n",
       "      <td>0.096151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MostPopularRecommender</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.264839</td>\n",
       "      <td>0.316762</td>\n",
       "      <td>0.371903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HighestRatedRecommender</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomRecommender</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.023333</td>\n",
       "      <td>0.043333</td>\n",
       "      <td>0.093333</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.017540</td>\n",
       "      <td>0.025715</td>\n",
       "      <td>0.041734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Recommender      HR@1      HR@3      HR@5     HR@10    NDCG@1  \\\n",
       "0         TFIDFRecommender  0.006667  0.053333  0.123333  0.233333  0.006667   \n",
       "0   MostPopularRecommender  0.166667  0.333333  0.460000  0.630000  0.166667   \n",
       "0  HighestRatedRecommender  0.000000  0.000000  0.000000  0.030000  0.000000   \n",
       "0        RandomRecommender  0.010000  0.023333  0.043333  0.093333  0.010000   \n",
       "\n",
       "     NDCG@3    NDCG@5   NDCG@10  \n",
       "0  0.033491  0.062178  0.096151  \n",
       "0  0.264839  0.316762  0.371903  \n",
       "0  0.000000  0.000000  0.009271  \n",
       "0  0.017540  0.025715  0.041734  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tfidf_recommender = TFIDFRecommender()\n",
    "tf_results = [['TFIDFRecommender'] + list(evaluate_leave_one_out_implicit(\n",
    "    tfidf_recommender, ml_ratings_df.loc[:, ['user_id', 'item_id']], ml_movies_df, max_evals=300, seed=6789))]\n",
    "\n",
    "tf_results = pd.DataFrame(tf_results, \n",
    "                       columns=['Recommender', 'HR@1', 'HR@3', 'HR@5', 'HR@10', 'NDCG@1', 'NDCG@3', 'NDCG@5', 'NDCG@10'])\n",
    "\n",
    "\n",
    "recommender = MostPopularRecommender()\n",
    "mp_results = [['MostPopularRecommender'] + list(evaluate_leave_one_out_implicit(\n",
    "    recommender, ml_ratings_df.loc[:, ['user_id', 'item_id']], ml_movies_df, max_evals=300, seed=6789))]\n",
    "\n",
    "mp_results = pd.DataFrame(mp_results, \n",
    "                       columns=['Recommender', 'HR@1', 'HR@3', 'HR@5', 'HR@10', 'NDCG@1', 'NDCG@3', 'NDCG@5', 'NDCG@10'])\n",
    "\n",
    "\n",
    "recommender = HighestRatedRecommender()\n",
    "hr_results = [['HighestRatedRecommender'] + list(evaluate_leave_one_out_implicit(\n",
    "    recommender, ml_ratings_df.loc[:, ['user_id', 'item_id', 'rating']], ml_movies_df, max_evals=300, seed=6789))]\n",
    "\n",
    "hr_results = pd.DataFrame(hr_results, \n",
    "                       columns=['Recommender', 'HR@1', 'HR@3', 'HR@5', 'HR@10', 'NDCG@1', 'NDCG@3', 'NDCG@5', 'NDCG@10'])\n",
    "\n",
    "\n",
    "recommender = RandomRecommender()\n",
    "r_results = [['RandomRecommender'] + list(evaluate_leave_one_out_implicit(\n",
    "    recommender, ml_ratings_df.loc[:, ['user_id', 'item_id', 'rating']], ml_movies_df, max_evals=300, seed=6789))]\n",
    "\n",
    "r_results = pd.DataFrame(r_results, \n",
    "                       columns=['Recommender', 'HR@1', 'HR@3', 'HR@5', 'HR@10', 'NDCG@1', 'NDCG@3', 'NDCG@5', 'NDCG@10'])\n",
    "\n",
    "\n",
    "result = pd.concat([tf_results, mp_results, hr_results, r_results])\n",
    "result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 7\\*.** Implement an SVRRecommender - one-hot encode genres and fit an SVR model to \n",
    "\n",
    "(genre_1, genre_2, ..., genre_N) -> rating\n",
    "\n",
    "Tune params of the SVR model to obtain as good results as you can. \n",
    "\n",
    "To do tuning properly (although in practive people are often happy with leave-one-out and do not bother with dividing the set into training, validation and test sets):\n",
    "    - divide the set into training, validation and test sets (randomly divide the dataset in proportions 60%-20%-20%),\n",
    "    - train the model with different sets of tunable parameters on the training set, \n",
    "    - choose the best tunable params based on results on the validation set, \n",
    "    - provide the final evaluation metrics on the test set for the best model obtained during tuning.\n",
    "\n",
    "Recommended method of tuning: use hyperopt. Install the package using the following command: `pip install hyperopt`\n",
    "    \n",
    "Print the RMSE and MAE on the test set generated with numpy with seed 6789."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting hyperopt\n",
      "  Downloading hyperopt-0.2.5-py2.py3-none-any.whl (965 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 965 kB 3.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /home/patryk/anaconda3/lib/python3.7/site-packages (from hyperopt) (1.12.0)\n",
      "Requirement already satisfied: tqdm in /home/patryk/anaconda3/lib/python3.7/site-packages (from hyperopt) (4.36.1)\n",
      "Requirement already satisfied: networkx>=2.2 in /home/patryk/anaconda3/lib/python3.7/site-packages (from hyperopt) (2.3)\n",
      "Requirement already satisfied: scipy in /home/patryk/anaconda3/lib/python3.7/site-packages (from hyperopt) (1.3.1)\n",
      "Requirement already satisfied: numpy in /home/patryk/anaconda3/lib/python3.7/site-packages (from hyperopt) (1.19.3)\n",
      "Requirement already satisfied: cloudpickle in /home/patryk/anaconda3/lib/python3.7/site-packages (from hyperopt) (1.2.2)\n",
      "Requirement already satisfied: future in /home/patryk/anaconda3/lib/python3.7/site-packages (from hyperopt) (0.17.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/patryk/anaconda3/lib/python3.7/site-packages (from networkx>=2.2->hyperopt) (4.4.0)\n",
      "Installing collected packages: hyperopt\n",
      "Successfully installed hyperopt-0.2.5\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "!pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "class SVRRecommender(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.mlb = None\n",
    "    \n",
    "    def fit(self, interactions_df, users_df, items_df): \n",
    "        print('in fit')\n",
    "        interactions_df = pd.merge(interactions_df, items_df, on='item_id')\n",
    "        interactions_df.loc[:, 'genres'] = interactions_df['genres'].str.replace(\"-\", \"_\", regex=False)\n",
    "        interactions_df.loc[:, 'genres'] = interactions_df['genres'].str.replace(\" \", \"_\", regex=False)\n",
    "        interactions_df.loc[:, 'genres'] = interactions_df['genres'].str.lower()\n",
    "        interactions_df.loc[:, 'genres'] = interactions_df['genres'].str.split(\"|\")\n",
    "        \n",
    "        self.mlb = MultiLabelBinarizer()\n",
    "        interactions_df = interactions_df.join(\n",
    "            pd.DataFrame(self.mlb.fit_transform(interactions_df.pop('genres')),\n",
    "                         columns=self.mlb.classes_,\n",
    "                         index=interactions_df.index))\n",
    "        \n",
    "        x = interactions_df.loc[:, self.mlb.classes_].values\n",
    "        y = interactions_df['rating'].values\n",
    "    \n",
    "        self.model = SVR(kernel='rbf', C=1.0, epsilon=0.1, gamma='scale').fit(x, y)\n",
    "        print('end fit')\n",
    "    \n",
    "    def recommend(self, users_df, items_df, n_recommendations=1):\n",
    "        \n",
    "        items_df = items_df.copy()\n",
    "        items_df.loc[:, 'genres'] = items_df['genres'].str.replace(\"-\", \"_\", regex=False)\n",
    "        items_df.loc[:, 'genres'] = items_df['genres'].str.replace(\" \", \"_\", regex=False)\n",
    "        items_df.loc[:, 'genres'] = items_df['genres'].str.lower()\n",
    "        items_df.loc[:, 'genres'] = items_df['genres'].str.split(\"|\")\n",
    "        \n",
    "        items_df = items_df.join(\n",
    "            pd.DataFrame(self.mlb.transform(items_df.pop('genres')),\n",
    "                         columns=self.mlb.classes_,\n",
    "                         index=items_df.index))\n",
    "    \n",
    "        recommendations = pd.DataFrame(columns=['user_id', 'item_id', 'score'])\n",
    "        \n",
    "        for ix, user in users_df.iterrows():\n",
    "            score = self.model.predict(items_df.loc[:, self.mlb.classes_].values)[0]\n",
    "                \n",
    "            user_recommendations = pd.DataFrame({'user_id': [user['user_id']],\n",
    "                                                 'item_id': items_df.iloc[0]['item_id'],\n",
    "                                                 'score': score})\n",
    "\n",
    "            recommendations = pd.concat([recommendations, user_recommendations])\n",
    "\n",
    "        return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before fit\n",
      "in fit\n",
      "end fit\n",
      "after fit\n",
      "counter =  0\n",
      "counter =  1000\n",
      "counter =  2000\n",
      "counter =  3000\n",
      "counter =  4000\n",
      "counter =  5000\n",
      "counter =  6000\n",
      "counter =  7000\n",
      "counter =  8000\n",
      "counter =  9000\n",
      "counter =  10000\n",
      "end evaluate train test split explicit\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recommender</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MRE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVRRecommender</td>\n",
       "      <td>1.017099</td>\n",
       "      <td>0.372203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "svr_recommender = SVRRecommender()\n",
    "\n",
    "results = [['SVRRecommender'] + list(evaluate_train_test_split_explicit(\n",
    "    svr_recommender, ml_ratings_df.loc[:, ['user_id', 'item_id', 'rating']], ml_movies_df, seed=6789))]\n",
    "\n",
    "results = pd.DataFrame(results, \n",
    "                       columns=['Recommender', 'RMSE', 'MRE'])\n",
    "\n",
    "display(HTML(results.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "class SVRRecommender2(object):\n",
    "    \n",
    "    def __init__(self, C, epsilon):\n",
    "        self.model = None\n",
    "        self.mlb = None\n",
    "        self.C = C\n",
    "        self.epsilon = epsilon\n",
    "    \n",
    "    def fit(self, interactions_df, users_df, items_df): \n",
    "        print('in fit')\n",
    "        interactions_df = pd.merge(interactions_df, items_df, on='item_id')\n",
    "        interactions_df.loc[:, 'genres'] = interactions_df['genres'].str.replace(\"-\", \"_\", regex=False)\n",
    "        interactions_df.loc[:, 'genres'] = interactions_df['genres'].str.replace(\" \", \"_\", regex=False)\n",
    "        interactions_df.loc[:, 'genres'] = interactions_df['genres'].str.lower()\n",
    "        interactions_df.loc[:, 'genres'] = interactions_df['genres'].str.split(\"|\")\n",
    "        \n",
    "        self.mlb = MultiLabelBinarizer()\n",
    "        interactions_df = interactions_df.join(\n",
    "            pd.DataFrame(self.mlb.fit_transform(interactions_df.pop('genres')),\n",
    "                         columns=self.mlb.classes_,\n",
    "                         index=interactions_df.index))\n",
    "        \n",
    "        x = interactions_df.loc[:, self.mlb.classes_].values\n",
    "        y = interactions_df['rating'].values\n",
    "    \n",
    "        self.model = SVR(kernel='rbf', C=self.C, epsilon=self.epsilon, gamma='scale').fit(x, y)\n",
    "        print('end fit')\n",
    "    \n",
    "    def recommend(self, users_df, items_df, n_recommendations=1):\n",
    "        \n",
    "        items_df = items_df.copy()\n",
    "        items_df.loc[:, 'genres'] = items_df['genres'].str.replace(\"-\", \"_\", regex=False)\n",
    "        items_df.loc[:, 'genres'] = items_df['genres'].str.replace(\" \", \"_\", regex=False)\n",
    "        items_df.loc[:, 'genres'] = items_df['genres'].str.lower()\n",
    "        items_df.loc[:, 'genres'] = items_df['genres'].str.split(\"|\")\n",
    "        \n",
    "        items_df = items_df.join(\n",
    "            pd.DataFrame(self.mlb.transform(items_df.pop('genres')),\n",
    "                         columns=self.mlb.classes_,\n",
    "                         index=items_df.index))\n",
    "    \n",
    "        recommendations = pd.DataFrame(columns=['user_id', 'item_id', 'score'])\n",
    "        \n",
    "        for ix, user in users_df.iterrows():\n",
    "            score = self.model.predict(items_df.loc[:, self.mlb.classes_].values)[0]\n",
    "                \n",
    "            user_recommendations = pd.DataFrame({'user_id': [user['user_id']],\n",
    "                                                 'item_id': items_df.iloc[0]['item_id'],\n",
    "                                                 'score': score})\n",
    "\n",
    "            recommendations = pd.concat([recommendations, user_recommendations])\n",
    "\n",
    "        return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before fit                                             \n",
      "in fit                                                 \n",
      "end fit                                                \n",
      "after fit                                              \n",
      "counter =                                              \n",
      "0                                                      \n",
      "counter =                                              \n",
      "1000                                                   \n",
      "counter =                                              \n",
      "2000                                                   \n",
      "counter =                                              \n",
      "3000                                                   \n",
      "counter =                                              \n",
      "4000                                                   \n",
      "counter =                                              \n",
      "5000                                                   \n",
      "counter =                                              \n",
      "6000                                                   \n",
      "counter =                                              \n",
      "7000                                                   \n",
      "counter =                                              \n",
      "8000                                                   \n",
      "counter =                                              \n",
      "9000                                                   \n",
      "counter =                                              \n",
      "10000                                                  \n",
      "end evaluate train test split explicit                 \n",
      "  0%|          | 0/100 [04:19<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: objective() missing 1 required positional argument: 'epsilon'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [04:19<?, ?trial/s, best loss=?]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "objective() missing 1 required positional argument: 'epsilon'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-1a6adfc8b24a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# ])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlognormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlognormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epsilon'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;31m# next line is where the fmin is actually executed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    290\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m                     \u001b[0;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    168\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"job exception: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    905\u001b[0m                 \u001b[0mprint_node_on_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrec_eval_print_node_on_error\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m             )\n\u001b[0;32m--> 907\u001b[0;31m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: objective() missing 1 required positional argument: 'epsilon'"
     ]
    }
   ],
   "source": [
    "import hyperopt.pyll\n",
    "from hyperopt import hp\n",
    "from hyperopt import fmin, tpe\n",
    "from hyperopt.pyll import scope\n",
    "\n",
    "# @scope.define\n",
    "def objective(C, epsilon):\n",
    "    recommender = SVRRecommender2(C, epsilon)\n",
    "    return evaluate_train_test_split_explicit(recommender, ml_ratings_df.loc[:, ['user_id', 'item_id', 'rating']], ml_movies_df, seed=6789)\n",
    "    \n",
    "# space = hp.choice('classifier_type', [\n",
    "#     {\n",
    "#         'type': 'svm',\n",
    "#         'C': hp.lognormal('C', 0, 1),\n",
    "#         'epsilon': hp.lognormal('epsilon', -0.1, 0.1)\n",
    "#     }\n",
    "# ])\n",
    "space = scope.objective(hp.lognormal('C', 0, 1), hp.lognormal('epsilon', -0.1, 0.1))\n",
    "best = fmin(objective, space, algo=tpe.suggest, max_evals=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
